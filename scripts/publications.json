{
    "collection": "publications",
    "data": [
        {
            "title": "FoVolNet: Fast Volume Rendering using Foveated Deep Neural Networks",
            "date": "2022-09-26",
            "venue": "IEEE Visualization Conference (VIS) [Best Paper Honorable Mentions]",
            "authors": "David Bauer, Qi Wu, and Kwan-Liu Ma",
            "abstract": "Volume data is found in many important scientific and engineering applications. Rendering this data for visualization at high quality and interactive rates for demanding applications such as virtual reality is still not easily achievable even using professional-grade hardware. We introduce FoVolNet—a method to significantly increase the performance of volume data visualization. We develop a cost-effective foveated rendering pipeline that sparsely samples a volume around a focal point and reconstructs the full-frame using a deep neural network. Foveated rendering is a technique that prioritizes rendering computations around the user’s focal point. This approach leverages properties of the human visual system, thereby saving computational resources when rendering data in the periphery of the user’s field of vision. Our reconstruction network combines direct and kernel prediction methods to produce fast, stable, and perceptually convincing output. With a slim design and the use of quantization, our method outperforms state-of-the-art neural reconstruction techniques in both end-to-end frame times and visual quality. We conduct extensive evaluations of the system’s rendering performance, inference speed, and perceptual properties, and we provide comparisons to competing neural image reconstruction techniques. Our test results show that FoVolNet consistently achieves significant time saving over conventional rendering while preserving perceptual quality.",
            "permalink": "vis2022-fovonet",
            "link": "https://drive.google.com/file/d/1-H7rtC_VH88oNp10kKSCacFE3IU2VCjj/view?usp=sharing",
            "citation": "Bauer, David, Qi Wu, and Kwan-Liu Ma. \"FoVolNet: Fast Volume Rendering Using Foveated Deep Neural Networks.\" IEEE Transactions on Visualization and Computer Graphics (VIS). 2022.",
            "bibtex": "@artivle{bauer2022fovolnet,\n author={Bauer, David and Wu, Qi and Ma, Kwan-Liu},\n journal={IEEE Transactions on Visualization and Computer Graphics}, \n title={FoVolNet: Fast Volume Rendering Using Foveated Deep Neural Networks}, \n year={2022},\n volume={},\n number={},\n pages={1-11},\n doi={10.1109/TVCG.2022.3209498}}"
        },
        {
            "title": "A Flexible Data Streaming Design for Interactive Visualization of Large-Scale Volume Data",
            "date": "2022-06-13",
            "venue": "The Eurographics Symposium on Parallel Graphics and Visualization (EGPGV)",
            "authors": "Qi Wu, Michael J. Doyle, and Kwan-Liu Ma",
            "abstract": "Modern simulations and experiments can produce massive amounts of high-fidelity data that are challenging to transport and visualize interactively. We have designed a data streaming system to support interactive visualization of large volume data. Our streaming system design is unique in its flexibility to support diverse data organizations and its coupling with a highly efficient CPU-based ray-tracing renderer. In this paper, we present our streaming and rendering design and demonstrate the efficacy of our system with progressive rendering of streaming tree-based AMR (TAMR) volume data and radial basis function (RBF) particle volume data. With our system, interactive visualization can be achieved using only a mid-range workstation with a single CPU and a modest quantity of RAM.",
            "permalink": "egpgv2022-streaming-volume",
            "link": "https://drive.google.com/file/d/13laOefDThpDUr-nxfpjTVLdTI2tiNpCi/view?usp=sharing",
            "citation": "Wu, Qi and Doyle, Michael J. and Ma, Kwan-Liu. \"A Flexible Data Streaming Design for Interactive Visualization of Large-Scale Volume Data.\" The Eurographics Symposium on Parallel Graphics and Visualization (EGPGV). (2022).",
            "bibtex": "@inproceedings{wu2022flexible,\nbooktitle = {Eurographics Symposium on Parallel Graphics and Visualization},\neditor = {Bujack, Roxana and Tierny, Julien and Sadlo, Filip},\ntitle = {{A Flexible Data Streaming Design for Interactive Visualization of Large-Scale Volume Data}},\nauthor = {Wu, Qi and Doyle, Michael J. and Ma, Kwan-Liu},\nyear = {2022},\npublisher = {The Eurographics Association},\nISSN = {1727-348X},\nISBN = {978-3-03868-175-5},\nDOI = {10.2312/pgv.20221064}\n}"
        },
        {
            "title": "DIVA: A Declarative and Reactive Language for in situ Visualization",
            "date": "2020-10-25",
            "venue": "IEEE Symposium on Large Data Analysis and Visualization (LDAV)",
            "authors": "Qi Wu, Tyson Neuroth, Oleg Igouchkine, Konduri Aditya, Jacqueline H. Chen, and Kwan-Liu Ma",
            "abstract": "The use of adaptive workflow management for in situ visualization and analysis has been a growing trend in large-scale scientific simulations. However, coordinating adaptive workflows with traditional procedural programming languages can be difficult because system flow is determined by unpredictable scientific phenomena, which often appear in an unknown order and can evade event handling. This makes the implementation of adaptive workflows tedious and error-prone. Recently, reactive and declarative programming paradigms have been recognized as well-suited solutions to similar problems in other domains. However, there is a dearth of research on adapting these approaches to in situ visualization and analysis. With this paper, we present a language design and runtime system for developing adaptive systems through a declarative and reactive programming paradigm. We illustrate how an adaptive workflow programming system is implemented using our approach and demonstrate it with a use case from a combustion simulation.",
            "permalink": "ldav2020-diva",
            "link": "https://drive.google.com/file/d/1i_D4LDDRNM_CSOoTgT6iE3a6D2yzbUr4/view?usp=sharing",
            "citation": "Wu, Qi, et al. \"DIVA: A Declarative and Reactive Language for in situ Visualization.\" IEEE Symposium on Large Data Analysis and Visualization (LDAV). 2020.",
            "bibtex": "@inproceedings{wu2020diva,\ntitle={{DIVA}: A Declarative and Reactive Language for in situ Visualization},\nauthor={Wu, Qi and Neuroth, Tyson and Igouchkine, Oleg and Aditya, Konduri and Chen, Jacqueline H and Ma, Kwan-Liu},\nbooktitle={2020 IEEE 10th Symposium on Large Data Analysis and Visualization (LDAV)},\npages={1--11},\nyear={2020},\norganization={IEEE}\n}"
        },
        {
            "title": "VisIt-OSPRay: toward an exascale volume visualization system",
            "date": "2018-06-04",
            "venue": "The Eurographics Symposium on Parallel Graphics and Visualization (EGPGV)",
            "authors": "Qi Wu, Will Usher, Steve Petruzza, Sidharth Kumar, Feng Wang, Ingo Wald, Valerio Pascucci, and Charles D. Hansen",
            "abstract": "Large-scale simulations can easily produce data in excess of what can be efficiently visualized using production visualization software, making it challenging for scientists to gain insights from the results of these simulations. This trend is expected to grow with exascale. To meet this challenge, and run on the highly parallel hardware being deployed on HPC system, rendering systems in production visualization software must be redesigned to perform well at these new scales and levels of parallelism. In this work, we present VisIt-OSPRay, a high-performance, scalable, hybrid-parallel rendering system in VisIt, using OSPRay and IceT, coupled with PIDX for scalable I/O. We examine the scalability and memory efficiency of this system and investigate further areas for improvement to prepare VisIt for upcoming exascale workloads.",
            "permalink": "egpgv2018-visit-ospray",
            "link": "https://drive.google.com/file/d/1ulrP4ogjIoxCR2A_oE9afemqhyK04lLA/view?usp=sharing",
            "citation": "Wu, Qi, et al. \"VisIt-OSPRay: toward an exascale volume visualization system.\" Proceedings of the Symposium on Parallel Graphics and Visualization. The Eurographics Symposium on Parallel Graphics and Visualization (EGPGV). 2018.",
            "bibtex": "@inproceedings{wu2018visit,\nauthor = {Wu, Qi and Usher, Will and Petruzza, Steve and Kumar, Sidharth and Wang, Feng and Wald, Ingo and Pascucci, Valerio and Hansen, Charles D.},\ntitle = {{VisIt-OSPRay}: Toward an Exascale Volume Visualization System},\nyear = {2018},\npublisher = {Eurographics Association},\naddress = {Goslar, DEU},\nbooktitle = {Proceedings of the Symposium on Parallel Graphics and Visualization},\npages = {13–24},\nnumpages = {12},\nlocation = {Brno, Czech Republic},\nseries = {EGPGV '18}\n}"
        },
        {
            "title": "CPU Isosurface Ray Tracing of Adaptive Mesh Refinement Data",
            "date": "2018-10-16",
            "venue": "IEEE Visualization Conference (VIS)",
            "authors": "Feng Wang, Ingo Wald, Qi Wu, Will Usher, and Chris R. Johnson",
            "abstract": "Adaptive mesh refinement (AMR) is a key technology for large-scale simulations that allows for adaptively changing the simulation mesh resolution, resulting in significant computational and storage savings. However, visualizing such AMR data poses a significant challenge due to the difficulties introduced by the hierarchical representation when reconstructing continuous field values. In this paper, we detail a comprehensive solution for interactive isosurface rendering of block-structured AMR data. We contribute a novel reconstruction strategy-the octant method-which is continuous, adaptive and simple to implement. Furthermore, we present a generally applicable hybrid implicit isosurface ray-tracing method, which provides better rendering quality and performance than the built-in sampling-based approach in OSPRay. Finally, we integrate our octant method and hybrid isosurface geometry into OSPRay as a module, providing the ability to create high-quality interactive visualizations combining volume and isosurface representations of BS-AMR data. We evaluate the rendering performance, memory consumption and quality of our method on two gigascale block-structured AMR datasets.",
            "permalink": "vis2018-impl",
            "link": "https://drive.google.com/file/d/1cNUeMO8X8hUjtTWlrVxslmeLOdq3vdyJ/view?usp=sharing",
            "citation": "Wang, Feng, et al. \"CPU isosurface ray tracing of adaptive mesh refinement data.\" IEEE Transactions on Visualization and Computer Graphics (VIS). 2018.",
            "bibtex": "@article{wang2018cpu,\nauthor={Wang, Feng and Wald, Ingo and Wu, Qi and Usher, Will and Johnson, Chris R.},\njournal={IEEE Transactions on Visualization and Computer Graphics}, \ntitle={CPU Isosurface Ray Tracing of Adaptive Mesh Refinement Data}, \nyear={2019},\nvolume={25},\nnumber={1},\npages={1142-1151},\ndoi={10.1109/TVCG.2018.2864850}\n}"
        },
        {
            "title": "Ray Tracing Generalized Tube Primitives: Method and Applications",
            "date": "2019-06-01",
            "venue": "Eurographics Conference on Visualization (EuroVis)",
            "authors": "Mengjiao Han, Ingo Wald, Will Usher, Qi Wu, Feng Wang, Valerio Pascucci, Charles D. Hansen, and Chris R. Johnson",
            "abstract": "We present a general high-performance technique for ray tracing generalized tube primitives. Our technique efficiently supports tube primitives with fixed and varying radii, general acyclic graph structures with bifurcations, and correct transparency with interior surface removal. Such tube primitives are widely used in scientific visualization to represent diffusion tensor imaging tractographies, neuron morphologies, and scalar or vector fields of 3D flow. We implement our approach within the OSPRay ray tracing framework, and evaluate it on a range of interactive visualization use cases of fixed- and varying-radius streamlines, pathlines, complex neuron morphologies, and brain tractographies. Our proposed approach provides interactive, high-quality rendering, with low memory overhead.",
            "permalink": "eurovis2019-tubes",
            "link": "https://drive.google.com/file/d/17pB_tIKD3jF6bVT1u9wpx9dwO_MqD-n6/view?usp=sharing",
            "citation": "Han, Mengjiao, et al. \"Ray tracing generalized tube primitives: Method and applications.\" Eurographics Conference on Visualization (EuroVis). 2019.",
            "bibtex": "@inproceedings{han2019ray,\ntitle={Ray tracing generalized tube primitives: Method and applications},\nauthor={Han, Mengjiao and Wald, Ingo and Usher, Will and Wu, Qi and Wang, Feng and Pascucci, Valerio and Hansen, Charles D. and Johnson, Chris R.},\nbooktitle={Computer Graphics Forum},\nvolume={38},\nnumber={3},\npages={467--478},\nyear={2019},\norganization={Wiley Online Library}\n}"
        }
    ]
}
